from typing import cast

import numpy as np
import pandas as pd
from catboost import CatBoostRegressor


class CatBoostLatLon:
    """
    CatBoost-–º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–º–µ—â–µ–Ω–∏–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (dlat, dlon).
    """

    def __init__(self, **params):
        """
        Parameters
        ----------
        **params : –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è CatBoostRegressor
        """
        default_params = {
            "loss_function": "MultiRMSE",
            "iterations": 2000,
            "learning_rate": 0.05,
            "depth": 6,
            "early_stopping_rounds": 200,
            "use_best_model": True,
            "random_seed": 42,
            "verbose": 0,
        }
        default_params.update(params)
        self.model = CatBoostRegressor(**default_params)
        self.feature_names_ = None
        self.is_fitted_ = False

    def fit(
        self,
        X: pd.DataFrame,
        y: pd.DataFrame,
        X_val: pd.DataFrame | None = None,
        y_val: pd.DataFrame | None = None,
        sample_weight: np.ndarray | None = None,
        sample_weight_val: np.ndarray | None = None,
        cat_features: list[str] | None = None,
    ):
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å.

        Parameters
        ----------
        X : pd.DataFrame
            –û–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        y : pd.DataFrame
            –û–±—É—á–∞—é—â–∏–µ —Ç–∞—Ä–≥–µ—Ç—ã (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å dlat_target, dlon_target)
        X_val : pd.DataFrame, optional
            –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        y_val : pd.DataFrame, optional
            –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–∞—Ä–≥–µ—Ç—ã
        sample_weight : np.ndarray, optional
            –í–µ—Å–∞ –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
        sample_weight_val : np.ndarray, optional
            –í–µ—Å–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
        cat_features : List[str], optional
            –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ["dlat_target", "dlon_target"]
        missing_cols = [col for col in required_cols if col not in y.columns]
        if missing_cols:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ y: {missing_cols}")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        y_train = y[required_cols]

        eval_set: list[tuple[pd.DataFrame, pd.DataFrame, np.ndarray | None]] | None = None
        if X_val is not None and y_val is not None:
            y_val_subset = y_val[required_cols]
            if sample_weight_val is not None:
                eval_set = [(X_val, y_val_subset, sample_weight_val)]
            else:
                eval_set = [cast(tuple[pd.DataFrame, pd.DataFrame, np.ndarray | None], (X_val, y_val_subset))]

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if cat_features is None:
            cat_features = ["target_time_hours", "grade"] if "grade" in X.columns else ["target_time_hours"]

        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        self.model.fit(X, y_train, eval_set=eval_set, sample_weight=sample_weight, cat_features=cat_features)

        self.feature_names_ = list(X.columns)
        self.is_fitted_ = True

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.

        Parameters
        ----------
        X : pd.DataFrame
            –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        Returns
        -------
        np.ndarray
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ñ–æ—Ä–º—ã (n_samples, 2) –¥–ª—è (dlat, dlon)
        """
        if not self.is_fitted_:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ fit() –ø–µ—Ä–µ–¥ predict()")

        return self.model.predict(X)

    @property
    def feature_importances_(self) -> np.ndarray:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
        if not self.is_fitted_:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        return self.model.feature_importances_

    @property
    def feature_names(self) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
        if not self.is_fitted_:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        return self.feature_names_


def calculate_sample_weights(X: pd.DataFrame, strategy: str = "long_horizon_focus") -> np.ndarray:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Å–∞ –¥–ª—è —Å—ç–º–ø–ª–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.

    Parameters
    ----------
    X : pd.DataFrame
        DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å target_time_hours)
    strategy : str
        –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è

    Returns
    -------
    np.ndarray
        –í–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
    """
    if "target_time_hours" not in X.columns:
        return np.ones(len(X))

    if strategy == "balanced_horizon":
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –º–µ–∂–¥—É –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º–∏
        horizon_counts = X["target_time_hours"].value_counts()
        max_count = horizon_counts.max()
        weights = X["target_time_hours"].map(lambda h: max_count / horizon_counts[h])

    elif strategy == "inverse_horizon":
        # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤
        max_horizon = X["target_time_hours"].max()
        weights = X["target_time_hours"].map(lambda h: max_horizon / h)

    elif strategy == "long_horizon_focus":
        # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è –¥–∞–ª—å–Ω–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ (–ª–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å)
        min_horizon = X["target_time_hours"].min()
        weights = X["target_time_hours"].map(lambda h: h / min_horizon)

    elif strategy == "long_horizon_quadratic":
        # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è –¥–∞–ª—å–Ω–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ (–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å)
        min_horizon = X["target_time_hours"].min()
        weights = X["target_time_hours"].map(lambda h: (h / min_horizon) ** 1.5)

    elif strategy == "distance_based":
        # –í–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–æ–Ω–æ–≤)
        if "speed_prev" in X.columns:
            speeds = X["speed_prev"].fillna(X["speed_prev"].median())
            max_speed = speeds.quantile(0.95)  # –∏–∑–±–µ–≥–∞–µ–º –≤—ã–±—Ä–æ—Å–æ–≤
            weights = (max_speed - speeds.clip(0, max_speed)) / max_speed + 0.1
        else:
            weights = pd.Series(1.0, index=X.index)

    else:
        weights = pd.Series(1.0, index=X.index)

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
    weights = weights / weights.mean()
    return weights.values


def train_model(
    X_train: pd.DataFrame,
    y_train: pd.DataFrame,
    X_val: pd.DataFrame,
    y_val: pd.DataFrame,
    use_weights: bool = True,
    weight_strategy: str = "long_horizon_focus",
    model_params: dict | None = None,
    verbose: bool = True,
) -> CatBoostLatLon:
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å CatBoost.

    Parameters
    ----------
    X_train, y_train : –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    X_val, y_val : –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    use_weights : bool
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –≤–µ—Å–∞ –¥–ª—è —Å—ç–º–ø–ª–æ–≤
    weight_strategy : str
        –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è
    model_params : Dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    verbose : bool
        –í—ã–≤–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—É—á–µ–Ω–∏–∏

    Returns
    -------
    CatBoostLatLon
        –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    if verbose:
        print(f"üìä –û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(X_train):,}")
        print(f"üìä –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")

        if "target_time_hours" in X_train.columns:
            horizon_counts = X_train["target_time_hours"].value_counts().sort_index()
            print("üìà –ü—Ä–∏–º–µ—Ä—ã –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º:")
            for h, count in horizon_counts.items():
                print(f"    {h:2.0f}—á: {count:5,} –ø—Ä–∏–º–µ—Ä–æ–≤")

    # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –¥–ª—è —Å—ç–º–ø–ª–æ–≤
    sample_weight = None
    if use_weights:
        sample_weight = calculate_sample_weights(X_train, strategy=weight_strategy)

        if verbose:
            print(f"‚öñÔ∏è –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤–µ—Å–∞ ({weight_strategy}):")
            print(f"   –ú–∏–Ω. –≤–µ—Å: {sample_weight.min():.3f}, –ú–∞–∫—Å. –≤–µ—Å: {sample_weight.max():.3f}")
            print(f"   –°—Ä–µ–¥–Ω–∏–π –≤–µ—Å: {sample_weight.mean():.3f}")

    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    params = model_params or {}
    model = CatBoostLatLon(**params)

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model.fit(X_train, y_train, X_val, y_val, sample_weight=sample_weight)

    if verbose:
        weight_info = f" —Å –≤–µ—Å–∞–º–∏ ({weight_strategy})" if use_weights else " –±–µ–∑ –≤–µ—Å–æ–≤"
        print(f"‚úÖ CatBoost –æ–±—É—á–µ–Ω{weight_info} (–º—É–ª—å—Ç–∏—Ä–µ–≥—Ä–µ—Å—Å–∏—è dlat –∏ dlon)")

    return model


class ModelTrainer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
    """

    def __init__(
        self,
        model_params: dict | None = None,
        use_weights: bool = True,
        weight_strategy: str = "balanced_horizon",
        verbose: bool = True,
    ):
        """
        Parameters
        ----------
        model_params : Dict, optional
            –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è CatBoost –º–æ–¥–µ–ª–∏
        use_weights : bool
            –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ—Å–∞ –¥–ª—è —Å—ç–º–ø–ª–æ–≤
        weight_strategy : str
            –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è
        verbose : bool
            –í—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
        """
        self.model_params = model_params or {}
        self.use_weights = use_weights
        self.weight_strategy = weight_strategy
        self.verbose = verbose
        self.model: CatBoostLatLon | None = None

    def train(
        self, X_train: pd.DataFrame, y_train: pd.DataFrame, X_val: pd.DataFrame, y_val: pd.DataFrame
    ) -> CatBoostLatLon:
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å.

        Returns
        -------
        CatBoostLatLon
            –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        self.model = train_model(
            X_train,
            y_train,
            X_val,
            y_val,
            use_weights=self.use_weights,
            weight_strategy=self.weight_strategy,
            model_params=self.model_params,
            verbose=self.verbose,
        )
        return self.model

    def get_feature_importance_analysis(self) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

        Returns
        -------
        Dict
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

        feature_importance = self.model.feature_importances_
        feature_names = self.model.feature_names

        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        importance_df = pd.DataFrame({"feature": feature_names, "importance": feature_importance}).sort_values(
            "importance", ascending=False
        )

        return {
            "importance_df": importance_df,
            "total_features": len(feature_names),
            "top_10_features": importance_df.head(10)["feature"].tolist(),
            "importance_stats": {
                "mean": feature_importance.mean(),
                "std": feature_importance.std(),
                "max": feature_importance.max(),
                "min": feature_importance.min(),
            },
        }
