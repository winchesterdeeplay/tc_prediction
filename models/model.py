from typing import Any, Self

import numpy as np
import onnx
import onnxruntime as ort
import pandas as pd
import pytorch_lightning as pl
import torch
from torch import nn
from torch.nn import Module
from torch.nn import TransformerEncoder, TransformerEncoderLayer

from core.coordinates import CoordinateProcessor
from core.features import FeatureConfig

from .losses import (
    CombinedCycloneLoss,
    HaversineLoss,
    NLLGaussianLoss,
    SectorLoss,
)


class SimpleTransformerModel(Module):
    def __init__(
        self,
        sequence_feature_dim: int,
        static_feature_dim: int = 5,
        hidden_dim: int = 64,
        num_layers: int = 2,
        num_heads: int = 8,
        dropout: float = 0.1,
        output_dim: int = 2,
        max_seq_length: int = 1000,
    ):
        super().__init__()

        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.static_feature_dim = static_feature_dim
        self.sequence_feature_dim = sequence_feature_dim
        self.max_seq_length = max_seq_length

        # –ü—Ä–æ–µ–∫—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∏—á –≤ hidden_dim
        self.input_projection = nn.Linear(sequence_feature_dim, hidden_dim)
        
        # Learnable Positional Encoding
        self.pos_encoding = nn.Parameter(torch.randn(max_seq_length, hidden_dim))
        
        # Sinusoidal Positional Encoding
        # self.register_buffer('pos_encoding', self._create_sinusoidal_encoding(max_seq_length, hidden_dim))
        
        # Transformer Encoder —Å–ª–æ–∏
        encoder_layer = TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=num_heads,
            dim_feedforward=hidden_dim * 4,
            dropout=dropout,
            batch_first=True,
            activation='relu'
        )
        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_layers, enable_nested_tensor=False)
        
        self.dropout = nn.Dropout(dropout)

        # –ì–æ–ª–æ–≤–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∏—á
        self.static_head = nn.Sequential(
            nn.Linear(static_feature_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
        )

        # –û–±—ä–µ–¥–∏–Ω—è—é—â–∏–π —Å–ª–æ–π
        combined_dim = hidden_dim + hidden_dim // 2
        self.combined_head = nn.Sequential(
            nn.Linear(combined_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
        )

        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        self.output_layer = nn.Linear(hidden_dim, output_dim)

    def _create_sinusoidal_encoding(self, max_len: int, d_model: int) -> torch.Tensor:
        """
        –°–æ–∑–¥–∞–µ—Ç sinusoidal positional encoding.
        
        Args:
            max_len: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            d_model: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            
        Returns:
            Positional encoding tensor [max_len, d_model]
        """
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        return pe

    def forward(
        self, sequences: torch.Tensor, static_features: torch.Tensor, seq_lengths: torch.Tensor
    ) -> torch.Tensor:
        """
        –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ Transformer –º–æ–¥–µ–ª—å.

        Parameters:
        ----------
        sequences : Tensor
            –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ [batch_size, seq_len, sequence_feature_dim]
        static_features : Tensor
            –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ [batch_size, static_feature_dim]
        seq_lengths : Tensor
            –î–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π [batch_size]

        Returns:
        ----------
        Tensor
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (dlat, dlon)
        """
        batch_size, seq_len, feature_dim = sequences.shape
        
        # –ü—Ä–æ–µ–∫—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∏—á
        x = self.input_projection(sequences)  # [batch_size, seq_len, hidden_dim]
        
        # –î–æ–±–∞–≤–ª—è–µ–º positional encoding
        pos_enc = self.pos_encoding[:seq_len, :].unsqueeze(0).expand(batch_size, -1, -1)
        x = x + pos_enc
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è padding (True –¥–ª—è padding —Ç–æ–∫–µ–Ω–æ–≤)
        mask = torch.arange(seq_len, device=sequences.device).unsqueeze(0) >= seq_lengths.unsqueeze(1)
        
        # Transformer Encoder –ø—Ä–æ—Ö–æ–¥
        transformer_out = self.transformer_encoder(x, src_key_padding_mask=mask)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        indices = torch.arange(batch_size, device=transformer_out.device)
        sequence_features = transformer_out[indices, seq_lengths - 1]
        
        # Dropout –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–Ω—ã—Ö —Ñ–∏—á
        sequence_features = self.dropout(sequence_features)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∏—á
        static_features = self.static_head(static_features)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∏—á–∏
        combined_features = torch.cat([sequence_features, static_features], dim=1)

        # –û–±—ä–µ–¥–∏–Ω—è—é—â–∏–π —Å–ª–æ–π
        combined_out = self.combined_head(combined_features)

        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        return self.output_layer(combined_out)  # type: ignore[no-any-return]





class NNLatLon(Module):
    """
    Neural Network model for predicting cyclone trajectory changes.

    Inherits from SimpleGRUModel but adds prediction capabilities.
    """

    def __init__(
        self, sequence_feature_dim: int, static_feature_dim: int = 5, hidden_dim: int = 128, num_layers: int = 2, num_heads: int = 8, output_dim: int = 2
    ):
        super().__init__()
        self.model = SimpleTransformerModel(sequence_feature_dim, static_feature_dim, hidden_dim, num_layers, num_heads, output_dim=output_dim)

    def forward(
        self, sequences: torch.Tensor, static_features: torch.Tensor, seq_lengths: torch.Tensor
    ) -> torch.Tensor:
        result: torch.Tensor = self.model(sequences, static_features, seq_lengths)
        return result

    def predict(self, x: pd.DataFrame, batch_size: int = 256) -> np.ndarray:
        """Predict on a dataframe.

        Parameters
        ----------
        x : pd.DataFrame
            DataFrame that contains a column with sequences and static features.
        batch_size : int
            Batch size for prediction.

        Returns
        -------
        np.ndarray
            Predictions.
        """
        feature_cfg = FeatureConfig()
        if feature_cfg.sequences_column not in x.columns:
            raise ValueError(f"DataFrame must contain '{feature_cfg.sequences_column}' column")

        return self._predict_dataframe(x, batch_size)

    def _predict_dataframe(self, x: pd.DataFrame, batch_size: int = 256) -> np.ndarray:
        """Predict from DataFrame with automatic padding."""
        if "sequences" not in x.columns:
            raise ValueError("DataFrame must contain 'sequences' column")

        device = next(self.parameters()).device

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏
        feature_cfg = FeatureConfig()
        sequences = [torch.tensor(seq, dtype=torch.float32) for seq in x[feature_cfg.sequences_column].tolist()]

        # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        static_cols = feature_cfg.static_features
        if all(col in x.columns for col in static_cols):
            static_features = torch.tensor(x[static_cols].values, dtype=torch.float32)
        else:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏: {static_cols}")

        preds: list[torch.Tensor] = []
        with torch.no_grad():
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            for i in range(0, len(sequences), batch_size):
                batch_sequences = sequences[i : i + batch_size]
                batch_static = static_features[i : i + batch_size]

                # –ü–∞–¥–¥–∏–Ω–≥ –¥–ª—è –±–∞—Ç—á–∞
                max_len = max(seq.size(0) for seq in batch_sequences)
                batch_size_actual = len(batch_sequences)
                feature_dim = batch_sequences[0].size(1)

                padded_batch = torch.zeros((batch_size_actual, max_len, feature_dim))
                seq_lengths = torch.zeros(batch_size_actual, dtype=torch.long)

                for j, seq in enumerate(batch_sequences):
                    seq_len = seq.size(0)
                    padded_batch[j, :seq_len] = seq
                    seq_lengths[j] = seq_len

                padded_batch = padded_batch.to(device)
                batch_static = batch_static.to(device)
                seq_lengths = seq_lengths.to(device)

                out = self.forward(padded_batch, batch_static, seq_lengths)
                preds.append(out.cpu())

        return torch.cat(preds).numpy()

    def fit(
        self,
        X_train: pd.DataFrame,
        y_train: pd.DataFrame,
        X_val: pd.DataFrame | None = None,
        y_val: pd.DataFrame | None = None,
        *,
        sample_weight: np.ndarray | None = None,
        criterion: nn.Module | None = None,
        batch_size: int = 64,
        epochs: int = 20,
        learning_rate: float = 1e-3,
        verbose: bool = True,
        save_on_interrupt: bool = False,
        interrupt_save_path: str = "nn_lat_lon.pt",
        shuffle_dataset: bool = False,
        **unused: Any,
    ) -> Self:
        """Simple supervised training loop.

        Parameters
        ----------
        X_train, y_train : pd.DataFrame
            Training feature/target data. ``X_train`` must contain sequences and static features.
        X_val, y_val : pd.DataFrame, optional
            Validation split. If ``None``, no validation will be performed.
        sample_weight : np.ndarray, optional
            Per-sample weights from the trainer.
        criterion : torch.nn.Module, optional
            Loss to optimise. Defaults to mean-squared error.
        batch_size, epochs, learning_rate : int | float
            Basic training hyper-parameters.
        verbose : bool
            If *True*, prints epoch progress.
        save_on_interrupt : bool
            If *True*, tries to save current parameters on ``KeyboardInterrupt``.
        interrupt_save_path : str
            Path where parameters will be stored.
        unused : dict
            Placeholder to absorb extra kwargs coming from ``ModelTrainer``.
        """
        from torch.utils.data import DataLoader

        from models.dataset import CycloneDataset, collate_variable_length

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.to(device)

        # ------------------------------------------------------------------
        # Dataset / loader
        # ------------------------------------------------------------------
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏, –≤–∫–ª—é—á–∞—è –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
        feature_cfg = FeatureConfig()
        static_cols = feature_cfg.static_features
        static_features_train = np.zeros((len(X_train), len(static_cols)), dtype=np.float32)
        for i, col in enumerate(static_cols):
            if col in X_train.columns:
                static_features_train[:, i] = X_train[col].values

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è loss —Ñ—É–Ω–∫—Ü–∏–π
        horizon_hours_train = X_train[feature_cfg.target_time_column].values.astype(np.float32)

        train_ds = CycloneDataset(
            sequences=X_train[feature_cfg.sequences_column].tolist(),
            static_features=static_features_train,
            y=y_train.values,
            horizon_hours=horizon_hours_train,
            sample_weight=sample_weight,
            shuffle_dataset=shuffle_dataset,
        )
        train_loader = DataLoader(
            train_ds,
            batch_size=batch_size,
            shuffle=True,
            collate_fn=collate_variable_length,
        )

        val_loader = None
        if X_val is not None and y_val is not None:
            static_features_val = np.zeros((len(X_val), len(static_cols)), dtype=np.float32)
            for i, col in enumerate(static_cols):
                if col in X_val.columns:
                    static_features_val[:, i] = X_val[col].values

            horizon_hours_val = X_val[feature_cfg.target_time_column].values.astype(np.float32)

            val_ds = CycloneDataset(
                sequences=X_val[feature_cfg.sequences_column].tolist(),
                static_features=static_features_val,
                y=y_val.values,
                horizon_hours=horizon_hours_val,
            )
            val_loader = DataLoader(
                val_ds,
                batch_size=batch_size,
                shuffle=False,
                collate_fn=collate_variable_length,
            )

        # ------------------------------------------------------------------
        # Optimiser / loss
        # ------------------------------------------------------------------
        if criterion is None:
            criterion = nn.MSELoss(reduction="none" if sample_weight is not None else "mean")
        optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)

        try:
            for epoch in range(1, epochs + 1):
                self.train()
                epoch_loss = 0.0
                batch_iter = train_loader
                if verbose:
                    from tqdm.auto import tqdm

                    batch_iter = tqdm(train_loader, desc=f"Epoch {epoch}/{epochs}", leave=False)

                for batch in batch_iter:
                    padded_seqs, static_features, targets, weights, horizon_hours, seq_lengths = batch
                    padded_seqs = padded_seqs.to(device)
                    static_features = static_features.to(device)
                    targets = targets.to(device)
                    seq_lengths = seq_lengths.to(device)
                    weights = weights.to(device)

                    optimiser.zero_grad()
                    preds = self(padded_seqs, static_features, seq_lengths)

                    loss_per_sample = criterion(preds, targets)
                    if loss_per_sample.dim() > 1:
                        loss_per_sample = loss_per_sample.mean(dim=1)

                    if sample_weight is not None:
                        loss_tensor = (loss_per_sample * weights).mean()
                    else:
                        loss_tensor = loss_per_sample.mean()
                    loss_tensor.backward()
                    optimiser.step()
                    epoch_loss += loss_tensor.item()

                epoch_loss /= len(train_loader)
                if verbose:
                    msg = f"Epoch {epoch:>3}/{epochs} | train_loss={epoch_loss:.4f}"
                    if val_loader is not None:
                        val_loss = _evaluate(self, val_loader, criterion, device)
                        msg += f" | val_loss={val_loss:.4f}"
                    from tqdm.auto import tqdm

                    tqdm.write(msg)

        except KeyboardInterrupt:
            if save_on_interrupt:
                print(f"\n‚ö†Ô∏è Training interrupted, saving checkpoint to {interrupt_save_path}")
                self.save(interrupt_save_path)
            raise

        return self

    def save(self, path: str) -> None:
        """Save model parameters to ``path`` using :pymeth:`torch.save`."""
        torch.save(self.state_dict(), path)


def _evaluate(model: "NNLatLon", loader: Any, criterion: Any, device: torch.device) -> float:
    """Utility evaluation on a *loader* returning average loss."""
    model.eval()
    total = 0.0
    with torch.no_grad():
        for batch in loader:
            padded_seqs, static_features, targets, weights, horizon_hours, seq_lengths = batch

            padded_seqs = padded_seqs.to(device)
            static_features = static_features.to(device)
            targets = targets.to(device)
            seq_lengths = seq_lengths.to(device)
            preds = model(padded_seqs, static_features, seq_lengths)
            loss_tensor = criterion(preds, targets).mean()
            total += loss_tensor.item()
    return total / len(loader)


class LightningCycloneModel(pl.LightningModule):
    """LightningModule that wraps NNLatLon and handles optimisation/logging."""

    def __init__(
        self,
        sequence_feature_dim: int,
        static_feature_dim: int = 5,
        hidden_dim: int = 128,
        num_layers: int = 2,
        num_heads: int = 8,
        learning_rate: float = 1e-3,
        loss_fn: str | nn.Module | None = None,
    ) -> None:
        super().__init__()
        self.save_hyperparameters()

        # Resolve loss function
        if loss_fn is None:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é horizon-aware loss –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            self.criterion: nn.Module = SectorLoss()
        elif isinstance(loss_fn, str):
            loss_name = loss_fn.lower()
            if loss_name in {"mse", "mseloss"}:
                self.criterion = nn.MSELoss()
            elif loss_name in {"sector", "sectorloss"}:
                self.criterion = SectorLoss()
            elif loss_name in {"nll", "gaussian", "negloglik", "nllgaussian"}:
                self.criterion = NLLGaussianLoss()
            elif loss_name in {"haversine", "haversineloss"}:
                self.criterion = HaversineLoss()
            elif loss_name in {"combined", "combinedcyclone", "combinedcycloneloss"}:
                self.criterion = CombinedCycloneLoss()
            else:
                raise ValueError(f"Unknown loss function: {loss_fn}")
        else:
            self.criterion = loss_fn

        output_dim = 4 if isinstance(self.criterion, (NLLGaussianLoss)) else 2
        self.net = NNLatLon(
            sequence_feature_dim=sequence_feature_dim,
            static_feature_dim=static_feature_dim,
            hidden_dim=hidden_dim,
            num_layers=num_layers,
            num_heads=num_heads,
            output_dim=output_dim,
        )
        self.learning_rate = learning_rate
        self.feature_cfg = FeatureConfig()

        self._criterion_handles_weights = isinstance(
            self.criterion,
            (
                SectorLoss,
                NLLGaussianLoss,
                HaversineLoss,
                CombinedCycloneLoss,
            ),
        )

    def forward(
        self, sequences: torch.Tensor, static_features: torch.Tensor, seq_lengths: torch.Tensor
    ) -> torch.Tensor:
        return self.net(sequences, static_features, seq_lengths)  # type: ignore[no-any-return]

    def export_to_onnx(
        self,
        filepath: str,
        sequence_length: int = 50,
        batch_size: int = 1,
        dynamic_axes: bool = True,
        opset_version: int = 13,
        validate: bool = True,
        device: str = "cpu",
    ) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –≤ ONNX —Ñ–æ—Ä–º–∞—Ç.

        Parameters
        ----------
        filepath : str
            –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ONNX —Ñ–∞–π–ª–∞
        sequence_length : int
            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        batch_size : int
            –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º)
        dynamic_axes : bool
            –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –æ—Å–∏ –¥–ª—è batch_size –∏ sequence_length
        opset_version : int
            –í–µ—Ä—Å–∏—è ONNX –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
        validate : bool
            –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
        """
        print(f"üîÑ –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –º–æ–¥–µ–ª–∏ –≤ ONNX...")
        self.eval()

        feature_cfg = FeatureConfig()
        feature_dims = feature_cfg.get_feature_dimensions()

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        dummy_sequences = torch.randn(batch_size, sequence_length, feature_dims["sequence"]).to(device)
        dummy_static = torch.randn(batch_size, feature_dims["static"]).to(device)
        dummy_lengths = torch.randint(1, sequence_length + 1, (batch_size,)).to(device)

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –æ—Å–∏
        if dynamic_axes:
            dynamic_axes_config = {
                "sequences": {0: "batch_size", 1: "sequence_length"},
                "static_features": {0: "batch_size"},
                "seq_lengths": {0: "batch_size"},
                "output": {0: "batch_size"},
            }
        else:
            dynamic_axes_config = None
            
        print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX...")
        
        torch.onnx.export(
            self.net,
            (dummy_sequences, dummy_static, dummy_lengths),
            filepath,
            export_params=True,
            opset_version=opset_version,
            do_constant_folding=True,
            input_names=["sequences", "static_features", "seq_lengths"],
            output_names=["output"],
            dynamic_axes=dynamic_axes_config,
            verbose=True,
            keep_initializers_as_inputs=False,
            export_modules_as_functions=False,
            dynamo=True
        )

        print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ ONNX: {filepath}")

        if validate:
            print("üîç –í–∞–ª–∏–¥–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            self._validate_onnx_model(filepath, dummy_sequences, dummy_static, dummy_lengths)

    def _validate_onnx_model(
        self, filepath: str, test_sequences: torch.Tensor, test_static: torch.Tensor, test_lengths: torch.Tensor
    ) -> None:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é ONNX –º–æ–¥–µ–ª—å.

        Parameters
        ----------
        filepath : str
            –ü—É—Ç—å –∫ ONNX —Ñ–∞–π–ª—É
        test_sequences : torch.Tensor
            –¢–µ—Å—Ç–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        test_static : torch.Tensor
            –¢–µ—Å—Ç–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏
        test_lengths : torch.Tensor
            –¢–µ—Å—Ç–æ–≤—ã–µ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º ONNX –º–æ–¥–µ–ª—å
            onnx_model = onnx.load(filepath)
            onnx.checker.check_model(onnx_model)

            # –°–æ–∑–¥–∞–µ–º ONNX Runtime —Å–µ—Å—Å–∏—é
            ort_session = ort.InferenceSession(filepath, providers=["CPUExecutionProvider"])

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è PyTorch –º–æ–¥–µ–ª–∏
            with torch.no_grad():
                pytorch_output = self.net(test_sequences, test_static, test_lengths).numpy()

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ONNX –º–æ–¥–µ–ª–∏
            onnx_inputs = {
                "sequences": test_sequences.numpy(),
                "static_features": test_static.numpy(),
                "seq_lengths": test_lengths.numpy(),
            }
            onnx_output = ort_session.run(None, onnx_inputs)[0]

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            diff = np.abs(pytorch_output - onnx_output).max()
            if diff < 1e-5:
                print(f"‚úÖ ONNX –º–æ–¥–µ–ª—å –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞: {diff:.2e}")
            else:
                print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É PyTorch –∏ ONNX –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏: {diff:.2e}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ONNX –º–æ–¥–µ–ª–∏: {e}")

    @staticmethod
    def load_onnx_model(filepath: str) -> ort.InferenceSession:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç ONNX –º–æ–¥–µ–ª—å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.

        Parameters
        ----------
        filepath : str
            –ü—É—Ç—å –∫ ONNX —Ñ–∞–π–ª—É

        Returns
        -------
        ort.InferenceSession
            ONNX Runtime —Å–µ—Å—Å–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        """
        return ort.InferenceSession(filepath, providers=["CPUExecutionProvider"])

    @staticmethod
    def predict_with_onnx(
        ort_session: ort.InferenceSession, sequences: np.ndarray, static_features: np.ndarray, seq_lengths: np.ndarray
    ) -> np.ndarray:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—è ONNX –º–æ–¥–µ–ª—å.

        Parameters
        ----------
        ort_session : ort.InferenceSession
            ONNX Runtime —Å–µ—Å—Å–∏—è
        sequences : np.ndarray
            –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ–∏—á [batch_size, seq_len, feature_dim]
        static_features : np.ndarray
            –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏ [batch_size, static_feature_dim]
        seq_lengths : np.ndarray
            –î–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π [batch_size]

        Returns
        -------
        np.ndarray
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [batch_size, output_dim]
        """
        try:
            inputs = {
                "sequences": sequences.astype(np.float32),
                "static_features": static_features.astype(np.float32),
                "seq_lengths": seq_lengths.astype(np.int64),
            }

            outputs = ort_session.run(None, inputs)
            return outputs[0]  # type: ignore[no-any-return]
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ ONNX –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            print(
                f"   –†–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–æ–≤: sequences={sequences.shape}, static_features={static_features.shape}, seq_lengths={seq_lengths.shape}"
            )
            raise

    @staticmethod
    def _validate_input(X: pd.DataFrame, feature_cfg: FeatureConfig) -> None:
        feature_cfg.validator.validate_sequences_format(X)

        static_features = feature_cfg.static_features
        missing_static = [col for col in static_features if col not in X.columns]
        if missing_static:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏: {missing_static}")

        if feature_cfg.sequences_column not in X.columns:
            raise ValueError(f"DataFrame must contain '{feature_cfg.sequences_column}' column")

        first_sequence = X[feature_cfg.sequences_column].iloc[0]
        if not isinstance(first_sequence, (list, np.ndarray)):
            raise ValueError(f"'{feature_cfg.sequences_column}' column must contain sequences (lists or arrays)")

    def predict(
        self,
        x: pd.DataFrame,
        batch_size: int = 256,
    ) -> np.ndarray:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ.

        Parameters
        ----------
        x : pd.DataFrame
            –î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ñ–∏—á–∞–º–∏
        batch_size : int
            –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        Returns
        -------
        np.ndarray
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        self._validate_input(x, self.feature_cfg)

        device = next(self.parameters()).device

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏
        sequences = [torch.tensor(seq, dtype=torch.float32) for seq in x[self.feature_cfg.sequences_column].tolist()]
        static_cols = self.feature_cfg.static_features
        if all(col in x.columns for col in static_cols):
            static_features = torch.tensor(x[static_cols].values, dtype=torch.float32)
        else:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏: {static_cols}")

        preds: list[torch.Tensor] = []
        with torch.no_grad():
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            for i in range(0, len(sequences), batch_size):
                batch_sequences = sequences[i : i + batch_size]
                batch_static = static_features[i : i + batch_size]

                # –ü–∞–¥–¥–∏–Ω–≥ –¥–ª—è –±–∞—Ç—á–∞
                max_len = max(seq.size(0) for seq in batch_sequences)
                batch_size_actual = len(batch_sequences)
                feature_dim = batch_sequences[0].size(1)

                padded_batch = torch.zeros((batch_size_actual, max_len, feature_dim))
                seq_lengths = torch.zeros(batch_size_actual, dtype=torch.long)

                for j, seq in enumerate(batch_sequences):
                    seq_len = seq.size(0)
                    padded_batch[j, :seq_len] = seq
                    seq_lengths[j] = seq_len

                padded_batch = padded_batch.to(device)
                batch_static = batch_static.to(device)
                seq_lengths = seq_lengths.to(device)

                out = self.forward(padded_batch, batch_static, seq_lengths)
                preds.append(out.cpu())

        return torch.cat(preds).numpy()

    def _shared_step(self, batch: Any, stage: str) -> torch.Tensor:
        """–û–±—â–∏–π —à–∞–≥ –¥–ª—è train –∏ validation."""
        padded_seqs, static_features, targets, weights, horizon_hours, seq_lengths = batch

        # Forward pass
        preds = self(padded_seqs, static_features, seq_lengths)

        # –í—ã—á–∏—Å–ª—è–µ–º loss
        if hasattr(self.criterion, "forward") and "horizon_hours" in self.criterion.forward.__code__.co_varnames:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º loss —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
            loss = self.criterion(preds, targets, horizon_hours=horizon_hours, sample_weight=weights)
        elif self._criterion_handles_weights:
            loss = self.criterion(preds, targets, sample_weight=weights)
        else:
            loss_tensor = self.criterion(preds, targets)
            if loss_tensor.dim() > 1:
                loss_tensor = loss_tensor.mean(dim=1)
            loss = (loss_tensor * weights).mean()

        # Log the learnable alpha parameter
        if hasattr(self.criterion, "learnable_norm") and hasattr(self.criterion.learnable_norm, "alpha"):
            alpha_value = self.criterion.learnable_norm.alpha
            if isinstance(alpha_value, (int, float)):
                self.log(f"{stage}_horizon_alpha", alpha_value, prog_bar=False, on_epoch=True)

        self.log(f"{stage}_loss", loss, prog_bar=True, on_step=True, on_epoch=True)
        return loss  # type: ignore[no-any-return]

    def training_step(self, batch: Any, batch_idx: int) -> torch.Tensor:
        return self._shared_step(batch, "train")

    def on_train_epoch_end(self) -> None:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏."""
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫—É –¥–ª—è 48-—á–∞—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._compute_train_48h_metric()

    def _compute_train_48h_metric(self) -> None:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫—É –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ 300 –∫–º —Å–µ–∫—Ç–æ—Ä –¥–ª—è 48-—á–∞—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ trainer
            if hasattr(self.trainer, "datamodule") and self.trainer.datamodule is not None:
                train_loader = self.trainer.datamodule.train_dataloader()

                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ —Ü–µ–ª–∏
                all_preds: list[torch.Tensor] = []
                all_targets: list[torch.Tensor] = []
                all_horizons: list[float] = []
                all_sequences: list[torch.Tensor] = []

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏
                was_training = self.training

                self.eval()
                with torch.no_grad():
                    for batch in train_loader:
                        padded_seqs, static_features, targets, weights, horizon_hours, seq_lengths = batch

                        preds = self(
                            padded_seqs.to(self.device), static_features.to(self.device), seq_lengths.to(self.device)
                        )

                        batch_size = preds.shape[0]
                        for i in range(batch_size):
                            all_preds.append(preds[i].cpu())
                            all_targets.append(targets[i])

                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
                            horizon = horizon_hours[i].cpu().item()
                            all_horizons.append(horizon)

                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                            all_sequences.append(padded_seqs[i])

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –æ–±—Ä–∞–∑—Ü—ã
                all_preds_tensor = torch.stack(all_preds, dim=0)
                all_targets_tensor = torch.stack(all_targets, dim=0)
                all_horizons_tensor = torch.tensor(all_horizons, dtype=torch.float32)

                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ 48-—á–∞—Å–æ–≤—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
                mask_48h = all_horizons_tensor == 48.0

                if mask_48h.sum() > 0:
                    preds_48h = all_preds_tensor[mask_48h]
                    targets_48h = all_targets_tensor[mask_48h]
                    sequences_48h = [all_sequences[i] for i in range(len(all_sequences)) if mask_48h[i].item()]

                    # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ –∫–∏–ª–æ–º–µ—Ç—Ä–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è haversine distance
                    errors_km = self._compute_haversine_errors_list(sequences_48h, targets_48h, preds_48h)

                    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ 300 –∫–º —Å–µ–∫—Ç–æ—Ä
                    p300_48h = (errors_km < 300.0).float().mean() * 100.0

                    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–µ
                    self.log("train_p300_48h", p300_48h, prog_bar=True, on_epoch=True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç 48-—á–∞—Å–æ–≤—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤, –ª–æ–≥–∏—Ä—É–µ–º 0
                    self.log("train_p300_48h", 0.0, prog_bar=True, on_epoch=True)

                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏
                if was_training:
                    self.train()

        except Exception as e:
            # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            print(f"Warning: Could not compute train 48h metric: {e}")
            # –õ–æ–≥–∏—Ä—É–µ–º 0 –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.log("train_p300_48h", 0.0, prog_bar=True, on_epoch=True)
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            if was_training:
                self.train()

    def validation_step(self, batch: Any, batch_idx: int) -> None:
        self._shared_step(batch, "val")

    def on_validation_epoch_end(self) -> None:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫—É –¥–ª—è 48-—á–∞—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
        self._compute_48h_metric()

    def _compute_48h_metric(self) -> None:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫—É –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ 300 –∫–º —Å–µ–∫—Ç–æ—Ä –¥–ª—è 48-—á–∞—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ trainer
            if hasattr(self.trainer, "datamodule") and self.trainer.datamodule is not None:
                val_loader = self.trainer.datamodule.val_dataloader()

                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ —Ü–µ–ª–∏
                all_preds: list[torch.Tensor] = []
                all_targets: list[torch.Tensor] = []
                all_horizons: list[float] = []
                all_sequences: list[torch.Tensor] = []

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏
                was_training = self.training

                self.eval()
                with torch.no_grad():
                    for batch in val_loader:
                        padded_seqs, static_features, targets, weights, horizon_hours, seq_lengths = batch

                        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                        preds = self(
                            padded_seqs.to(self.device), static_features.to(self.device), seq_lengths.to(self.device)
                        )

                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –æ–±—Ä–∞–∑–µ—Ü –æ—Ç–¥–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏
                        batch_size = preds.shape[0]
                        for i in range(batch_size):
                            all_preds.append(preds[i].cpu())
                            all_targets.append(targets[i])

                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
                            horizon = horizon_hours[i].cpu().item()
                            all_horizons.append(horizon)

                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                            all_sequences.append(padded_seqs[i])

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –æ–±—Ä–∞–∑—Ü—ã
                all_preds_tensor = torch.stack(all_preds, dim=0)
                all_targets_tensor = torch.stack(all_targets, dim=0)
                all_horizons_tensor = torch.tensor(all_horizons, dtype=torch.float32)

                mask_48h = all_horizons_tensor == 48.0

                if torch.sum(mask_48h) > 0:
                    preds_48h = all_preds_tensor[mask_48h]
                    targets_48h = all_targets_tensor[mask_48h]
                    sequences_48h = [all_sequences[i] for i in range(len(all_sequences)) if mask_48h[i].item()]

                    # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ –∫–∏–ª–æ–º–µ—Ç—Ä–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è haversine distance
                    errors_km = self._compute_haversine_errors_list(sequences_48h, targets_48h, preds_48h)

                    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ 300 –∫–º —Å–µ–∫—Ç–æ—Ä
                    p300_48h = (errors_km < 300.0).float().mean() * 100.0

                    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–µ
                    self.log("val_p300_48h", p300_48h, prog_bar=True, on_epoch=True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç 48-—á–∞—Å–æ–≤—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤, –ª–æ–≥–∏—Ä—É–µ–º 0
                    self.log("val_p300_48h", 0.0, prog_bar=True, on_epoch=True)

                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏
                if was_training:
                    self.train()

        except Exception as e:
            # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            print(f"Warning: Could not compute 48h metric: {e}")
            # –õ–æ–≥–∏—Ä—É–µ–º 0 –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.log("val_p300_48h", 0.0, prog_bar=True, on_epoch=True)
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            if was_training:
                self.train()

    def _compute_haversine_errors(
        self, sequences: torch.Tensor, targets: torch.Tensor, predictions: torch.Tensor
    ) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—à–∏–±–∫–∏ –≤ –∫–∏–ª–æ–º–µ—Ç—Ä–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è haversine distance."""
        coord_processor = CoordinateProcessor()
        errors_km = []

        for i in range(len(sequences)):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            curr_lat, curr_lon = self._extract_current_coords(sequences[i])

            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            pred_lat = curr_lat + predictions[i, 0].item()
            pred_lon = curr_lon + predictions[i, 1].item()

            # –ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            true_lat = curr_lat + targets[i, 0].item()
            true_lon = curr_lon + targets[i, 1].item()

            # –í—ã—á–∏—Å–ª—è–µ–º haversine distance
            error_km = coord_processor.haversine_distance(true_lat, true_lon, pred_lat, pred_lon)
            errors_km.append(error_km)

        return torch.tensor(errors_km, dtype=torch.float32)

    def _compute_haversine_errors_list(
        self, sequences: list[torch.Tensor], targets: torch.Tensor, predictions: torch.Tensor
    ) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—à–∏–±–∫–∏ –≤ –∫–∏–ª–æ–º–µ—Ç—Ä–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è haversine distance –¥–ª—è —Å–ø–∏—Å–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π."""
        coord_processor = CoordinateProcessor()
        errors_km = []

        for i in range(len(sequences)):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            curr_lat, curr_lon = self._extract_current_coords(sequences[i])

            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            pred_lat = curr_lat + predictions[i, 0].item()
            pred_lon = curr_lon + predictions[i, 1].item()

            # –ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            true_lat = curr_lat + targets[i, 0].item()
            true_lon = curr_lon + targets[i, 1].item()

            # –í—ã—á–∏—Å–ª—è–µ–º haversine distance
            error_km = coord_processor.haversine_distance(true_lat, true_lon, pred_lat, pred_lon)
            errors_km.append(error_km)

        return torch.tensor(errors_km, dtype=torch.float32)

    def _extract_current_coords(self, seq: torch.Tensor) -> tuple[float, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–µ–ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        non_zero_mask = (seq != 0).any(dim=1)
        if non_zero_mask.any():
            last_idx = int(torch.where(non_zero_mask)[0][-1])
            return float(seq[last_idx, 0]), float(seq[last_idx, 1])
        return 0.0, 0.0

    def configure_optimizers(self) -> dict[str, Any]:  # type: ignore[override]
        optimiser = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, mode="min", factor=0.5, patience=3)
        return {
            "optimizer": optimiser,
            "lr_scheduler": {
                "scheduler": scheduler,
                "monitor": "val_loss_epoch",
                "interval": "epoch",
                "frequency": 1,
            },
        }
