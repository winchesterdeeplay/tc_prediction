import time
import logging
from typing import Any
from pathlib import Path

from inference import ONNXInferencePipeline, ONNXInferencePipelineFactory
from .models import CycloneData, Prediction, cyclone_data_to_dataframe, dataframe_to_predictions, ModelInfoResponse


class CyclonePredictionService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π —Ü–∏–∫–ª–æ–Ω–æ–≤."""

    def __init__(self, model_path: str, pipeline_type: str = "fast", sequence_config: dict | None = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.

        Parameters
        ----------
        model_path : str
            –ü—É—Ç—å –∫ ONNX –º–æ–¥–µ–ª–∏
        pipeline_type : str
            –¢–∏–ø –ø–∞–π–ø–ª–∞–π–Ω–∞: "fast", "memory", "gpu"
        sequence_config : dict, optional
            –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        """
        self.model_path = Path(model_path)
        self.pipeline_type = pipeline_type
        self.sequence_config = sequence_config or {"min_history_length": 1, "max_history_length": 50}

        self._pipeline: ONNXInferencePipeline | None = None
        self._load_pipeline()

        logging.info(f"‚úÖ –°–µ—Ä–≤–∏—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é: {model_path}")

    def _load_pipeline(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–π–ø–ª–∞–π–Ω –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞."""
        try:
            if self.pipeline_type == "fast":
                self._pipeline = ONNXInferencePipelineFactory.create_fast_inference(
                    str(self.model_path), self.sequence_config
                )
            elif self.pipeline_type == "memory":
                self._pipeline = ONNXInferencePipelineFactory.create_memory_efficient(
                    str(self.model_path), self.sequence_config
                )
            elif self.pipeline_type == "gpu":
                self._pipeline = ONNXInferencePipelineFactory.create_gpu_inference(
                    str(self.model_path), self.sequence_config
                )
            else:
                self._pipeline = ONNXInferencePipeline(str(self.model_path), sequence_config=self.sequence_config)

            logging.info(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω —Ç–∏–ø–∞ '{self.pipeline_type}' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω: {e}")

    def predict(self, cyclone_data: list[CycloneData], horizon_hours: int, batch_size: int = 256) -> dict[str, Any]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ü–∏–∫–ª–æ–Ω–æ–≤.

        Parameters
        ----------
        cyclone_data : list[CycloneData]
            –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–∏–∫–ª–æ–Ω–∞—Ö
        horizon_hours : int
            –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ —á–∞—Å–∞—Ö
        batch_size : int
            –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

        Returns
        -------
        dict[str, Any]
            –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if self._pipeline is None:
            raise RuntimeError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        start_time = time.time()

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ DataFrame
            df = cyclone_data_to_dataframe(cyclone_data)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            predictions_df = self._pipeline.predict(df=df, horizon_hours=horizon_hours, batch_size=batch_size)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            predictions_dict = dataframe_to_predictions(predictions_df)
            predictions = [Prediction(**pred) for pred in predictions_dict]

            processing_time = (time.time() - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

            return {
                "predictions": predictions,
                "horizon_hours": horizon_hours,
                "total_predictions": len(predictions),
                "processing_time_ms": round(processing_time, 2),
            }

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")

    def predict_multiple_horizons(
        self, cyclone_data: list[CycloneData], horizons: list[int] = [6, 12, 24, 48], batch_size: int = 256
    ) -> dict[str, Any]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤.

        Parameters
        ----------
        cyclone_data : list[CycloneData]
            –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–∏–∫–ª–æ–Ω–∞—Ö
        horizons : list[int]
            –°–ø–∏—Å–æ–∫ –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞
        batch_size : int
            –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

        Returns
        -------
        dict[str, Any]
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º
        """
        if self._pipeline is None:
            raise RuntimeError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        start_time = time.time()

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ DataFrame
            df = cyclone_data_to_dataframe(cyclone_data)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤
            results = self._pipeline.predict_multiple_horizons(df=df, horizons=horizons, batch_size=batch_size)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            predictions_by_horizon = {}
            total_predictions = 0

            for horizon, result_df in results.items():
                if result_df is not None:
                    predictions_dict = dataframe_to_predictions(result_df)
                    predictions = [Prediction(**pred) for pred in predictions_dict]
                    predictions_by_horizon[str(horizon)] = predictions
                    total_predictions += len(predictions)
                else:
                    predictions_by_horizon[str(horizon)] = []

            processing_time = (time.time() - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

            return {
                "predictions": predictions_by_horizon,
                "horizons": horizons,
                "total_predictions": total_predictions,
                "processing_time_ms": round(processing_time, 2),
            }

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤: {e}")
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤: {e}")

    def get_model_info(self) -> ModelInfoResponse:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏.

        Returns
        -------
        ModelInfoResponse
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        """
        if self._pipeline is None:
            raise RuntimeError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        try:
            model_info = self._pipeline.get_model_info()

            # Ensure proper typing for the model info values
            inputs = model_info.get("inputs", [])
            if not isinstance(inputs, list):
                inputs = []
            # Ensure all elements are strings
            inputs = [str(x) for x in inputs]

            outputs = model_info.get("outputs", [])
            if not isinstance(outputs, list):
                outputs = []
            # Ensure all elements are strings
            outputs = [str(x) for x in outputs]

            providers = model_info.get("providers", [])
            if not isinstance(providers, list):
                providers = []
            # Ensure all elements are strings
            providers = [str(x) for x in providers]

            feature_dimensions = model_info.get("feature_dimensions", {})
            if not isinstance(feature_dimensions, dict):
                feature_dimensions = {}
            # Ensure all values are integers
            feature_dimensions = {str(k): int(v) for k, v in feature_dimensions.items()}

            return ModelInfoResponse(
                model_path=str(self.model_path),
                inputs=inputs,
                outputs=outputs,
                providers=providers,
                feature_dimensions=feature_dimensions,
            )

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏: {e}")
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏: {e}")

    def is_healthy(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ —Å–µ—Ä–≤–∏—Å–∞.

        Returns
        -------
        bool
            True –µ—Å–ª–∏ —Å–µ—Ä–≤–∏—Å –∑–¥–æ—Ä–æ–≤
        """
        return self._pipeline is not None and self.model_path.exists()

    def reload_model(self) -> None:
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å."""
        logging.info("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        self._load_pipeline()
        logging.info("‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
